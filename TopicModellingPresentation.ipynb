{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tematsko modeliranje - prezentacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem kojim se tematsko modeliranje bavi je pronalaženje načina da se nađu teme nekog zadatog teksta. Ovde se podrazumeva da nam je na raspolaganju veliki skup (odnosno, *korpus*) tekstova.\n",
    "\n",
    "Korpus tekstova koji je korišćen je `20 Newsgroup` koji je dostupan u `sklearn` biblioteci i on izgleda ovako:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            document\n",
      "0  Subject: Re: \"Imaginary\" Friends - Dragons & M...\n",
      "1  From: ivan@IRO.UMontreal.CA (Catalin Ivan)\\nSu...\n",
      "2  From: JOEL@jach.hawaii.edu (Joel Aycock)\\nSubj...\n",
      "3  From: cds7k@Virginia.EDU (Christopher Douglas ...\n",
      "4  From: drw3l@delmarva.evsc.Virginia.EDU (David ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_20newsgroups(shuffle=True, random_state=5).data\n",
    "news_df = pd.DataFrame({\"document\":data})\n",
    "print(news_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jasno je da se dokumenti, kao ovakvi, ne mogu koristiti za metode tematskog modeliranja. Zbog toga je neophodno odstranjivanje svega što nije slovo, pa onda pretvaranje svih slova u mala slova. Brisanje kraćih reči je takođe poželjno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon predprocesiranja teksta, potrebno je korpus sa rečima transformisati u nekakav numerički oblik, tako da svaka reč bude reprezenovana težinom koja se odnosi na frekvenciju pojavljivanja te reči. Ovde je koriščen `TfidfVectorizer` iz `sklearn`, ali je moguće koristiti i `CountVectorizer` iz iste biblioteke. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na kraju dolazimo do metoda koje su korišćene: LSA i LDA. \n",
    "\n",
    "LSA se zasniva na pristupu smanjenja dimenzionalnosti tzv. dokument-term matrice dobijene nakon korišćenja `TfidfVectorizer` uz pomoć singularne dekompozicije.\n",
    "\n",
    "U tekstu je nakratko pomenut i PLSA algoritam koji, za razliku od LSA, pravi probabilistički model u svrhe rešavanja problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA je pristup koji se drastično razlikuje od LSA po tome što svodimo problem tematskog modeliranja na problem optimizacije (detaljnije opisan u tekstu). Ovaj pristup je daleko manje intuitivan od LSA algoritma, budući da koristi kompleksne osobine Bajesove verovatnoće, ali postiže dobre rezultate u praksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I za LSA i za LDA postoje odgovarajući objekti u biblioteci `sklearn` koji omogućavaju jednostavnu upotrebu. Za LDA se takođe koristi i implementacija u okviru `gensim` biblioteke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korišćeni materijali:\n",
    "\n",
    "[Topic Modeling with LSA, PLSA, LDA & lda2Vec](https://medium.com/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05)\n",
    "\n",
    "[Text Mining 101: A Stepwise Introduction to Topic Modeling using Latent Semantic Analysis (using Python)](https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/)\n",
    "\n",
    "[Topic Modelling with LSA and LDA](https://forestforthetree.com/statistics/2018/01/28/topic-modelling-with-lsa-and-lda.html)\n",
    "\n",
    "[Intuitive Guide to Latent Dirichlet Allocation](https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158)\n",
    "\n",
    "[Latent Dirichlet Allocation, original paper](https://ai.stanford.edu/~ang/papers/jair03-lda.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitdc7810f74838480dabcd7f02ae4f8b21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
